{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7718643,"sourceType":"datasetVersion","datasetId":4508245}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Reshape, Dropout, Dense\nfrom tensorflow.keras.layers import Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Activation, ZeroPadding2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom PIL import Image\nimport os\nimport time\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GENERATE_RES = 3\nGENERATE_SQUARE = 32 * GENERATE_RES\nIMAGE_CHANNELS = 3\n\nPREVIEW_ROWS = 4\nPREVIEW_COLS = 7\nPREVIEW_MARGIN = 16\n\nSEED_SIZE = 100\n\n# Adjust the data path for VScode directory structure\nDATA_PATH = '/kaggle/input/fresh-apple-and-rotten-apple/rotten'\n\nEPOCHS = 3000\nBATCH_SIZE = 32\nBUFFER_SIZE = 60000\n\nprint(f\"Will generate {GENERATE_SQUARE}px square images.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create TensorFlow dataset\ntrain_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    DATA_PATH,\n    labels=None,\n    label_mode=None,\n    batch_size=BATCH_SIZE,\n    image_size=(GENERATE_SQUARE, GENERATE_SQUARE),\n    shuffle=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing the images to [-1, 1]\ntrain_dataset = train_dataset.map(lambda x: (x - 127.5) / 127.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generator model\ndef build_generator(seed_size, channels):\n    model = Sequential()\n    model.add(Dense(4*4*256, activation=\"relu\", input_dim=seed_size))\n    model.add(Reshape((4, 4, 256)))\n    model.add(UpSampling2D())\n    model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(UpSampling2D())\n    model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    \n    if GENERATE_RES > 1:\n        model.add(UpSampling2D(size=(GENERATE_RES, GENERATE_RES)))\n        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Activation(\"relu\"))\n\n    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Discriminator model\ndef build_discriminator(image_shape):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_images(cnt, noise):\n    image_array = np.full((PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE + PREVIEW_MARGIN)),\n                           PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE + PREVIEW_MARGIN)), 3),\n                          255, dtype=np.uint8)\n\n    generated_images = generator.predict(noise)\n    generated_images = 0.5 * generated_images + 0.5\n\n    image_count = 0\n    for row in range(PREVIEW_ROWS):\n        for col in range(PREVIEW_COLS):\n            r = row * (GENERATE_SQUARE + 16) + PREVIEW_MARGIN\n            c = col * (GENERATE_SQUARE + 16) + PREVIEW_MARGIN\n            image_array[r:r + GENERATE_SQUARE, c:c + GENERATE_SQUARE] = generated_images[image_count] * 255\n            image_count += 1\n\n    output_path = '/kaggle/working/samples'\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    filename = os.path.join(output_path, f\"train-{cnt}.png\")\n    im = Image.fromarray(image_array)\n    im.save(filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\nnoise = tf.random.normal([1, SEED_SIZE])\ngenerated_image = generator(noise, training=False)\nplt.imshow((generated_image[0] * 0.5 + 0.5).numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_shape = (GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\ndiscriminator = build_discriminator(image_shape)\ndecision = discriminator(generated_image)\nprint(decision)\n\ncross_entropy = tf.keras.losses.BinaryCrossentropy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1.5e-4, 0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4, 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define your checkpoint directory and manager\ncheckpoint_dir = '/kaggle/working/checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to restore the latest checkpoint\ndef restore_checkpoint():\n    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n    if latest_checkpoint:\n        checkpoint.restore(latest_checkpoint)\n        print(f\"Checkpoint restored from {latest_checkpoint}\")\n    else:\n        print(\"No checkpoint found, initializing from scratch.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(images):\n    seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(seed, training=True)\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    \n    return gen_loss, disc_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataset, epochs):\n    fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\n    start = time.time()\n\n    for epoch in range(epochs):\n        epoch_start = time.time()\n\n        gen_loss_list = []\n        disc_loss_list = []\n\n        for image_batch in dataset:\n            t = train_step(image_batch)\n            gen_loss_list.append(t[0])\n            disc_loss_list.append(t[1])\n\n        g_loss = sum(gen_loss_list) / len(gen_loss_list)\n        d_loss = sum(disc_loss_list) / len(disc_loss_list)\n\n        epoch_elapsed = time.time() - epoch_start\n        print(f'Epoch {epoch + 1}, gen loss={g_loss}, disc loss={d_loss}, time={epoch_elapsed:.2f}s')\n\n        if (epoch + 1) % 50 == 0:\n            checkpoint.save(file_prefix=checkpoint_prefix)\n            save_images(epoch, fixed_seed)\n\n    elapsed = time.time() - start\n    print(f'Training time: {elapsed:.2f}s')\n    \ntrain(train_dataset, EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the final model after training\ntf.keras.models.save_model(generator, '/kaggle/working/generator.keras')\ntf.keras.models.save_model(discriminator, '/kaggle/working/discriminator.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}